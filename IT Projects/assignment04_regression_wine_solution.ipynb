{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41069436",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Assignment #4 (demo). Exploring OLS, Lasso and Random Forest in a regression task. Solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3270062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso, LassoCV, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import (GridSearchCV, cross_val_score,\n",
    "                                     train_test_split)\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9003b3f",
   "metadata": {},
   "source": [
    "**We are working with UCI Wine quality dataset (no need to download it â€“ it's already there, in course repo and in Kaggle Dataset).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ede775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Jupyter-book, we copy data from GitHub, locally, to save Internet traffic,\n",
    "# you can specify the data/ folder from the root of your cloned\n",
    "# https://github.com/Yorko/mlcourse.ai repo, to save Internet traffic\n",
    "DATA_PATH = \"https://raw.githubusercontent.com/Yorko/mlcourse.ai/master/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6c4485",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATA_PATH + \"winequality-white.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baffd2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7644153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636b2911",
   "metadata": {},
   "source": [
    "**Separate the target feature, split data in 7:3 proportion (30% form a holdout set, use random_state=17), and preprocess data with `StandardScaler`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a65295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"quality\"]\n",
    "X = data.drop(\"quality\", axis=1)\n",
    "\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=17\n",
    ")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_holdout_scaled = scaler.transform(X_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8badc8c6",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "\n",
    "**Train a simple linear regression model (Ordinary Least Squares).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a701967",
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train_scaled, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18c5575",
   "metadata": {},
   "source": [
    "**<font color='red'>Question 1:</font> What are mean squared errors of model predictions on train and holdout sets?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5610f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Mean squared error (train): %.3f\"\n",
    "    % mean_squared_error(y_train, linreg.predict(X_train_scaled))\n",
    ")\n",
    "print(\n",
    "    \"Mean squared error (test): %.3f\"\n",
    "    % mean_squared_error(y_holdout, linreg.predict(X_holdout_scaled))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf0f467",
   "metadata": {},
   "source": [
    "**Sort features by their influence on the target feature (wine quality). Beware that both large positive and large negative coefficients mean large influence on target. It's handy to use `pandas.DataFrame` here.**\n",
    "\n",
    "**<font color='red'>Question 2:</font> Which feature this linear regression model treats as the most influential on wine quality?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a38495",
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_coef = pd.DataFrame(\n",
    "    {\"coef\": linreg.coef_, \"coef_abs\": np.abs(linreg.coef_)},\n",
    "    index=data.columns.drop(\"quality\"),\n",
    ")\n",
    "linreg_coef.sort_values(by=\"coef_abs\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ef3786",
   "metadata": {},
   "source": [
    "## Lasso regression\n",
    "\n",
    "**Train a LASSO model with $\\alpha = 0.01$ (weak regularization) and scaled data. Again, set random_state=17.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db28552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso1 = Lasso(alpha=0.01, random_state=17)\n",
    "lasso1.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8470962",
   "metadata": {},
   "source": [
    "**Which feature is the least informative in predicting wine quality, according to this LASSO model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972d800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso1_coef = pd.DataFrame(\n",
    "    {\"coef\": lasso1.coef_, \"coef_abs\": np.abs(lasso1.coef_)},\n",
    "    index=data.columns.drop(\"quality\"),\n",
    ")\n",
    "lasso1_coef.sort_values(by=\"coef_abs\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21459e95",
   "metadata": {},
   "source": [
    "**Train LassoCV with random_state=17 to choose the best value of $\\alpha$ in 5-fold cross-validation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e73658",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-6, 2, 200)\n",
    "lasso_cv = LassoCV(random_state=17, cv=5, alphas=alphas)\n",
    "lasso_cv.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967e7ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd947a1",
   "metadata": {},
   "source": [
    "**<font color='red'>Question 3:</font> Which feature is the least informative in predicting wine quality, according to the tuned LASSO model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac760341",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv_coef = pd.DataFrame(\n",
    "    {\"coef\": lasso_cv.coef_, \"coef_abs\": np.abs(lasso_cv.coef_)},\n",
    "    index=data.columns.drop(\"quality\"),\n",
    ")\n",
    "lasso_cv_coef.sort_values(by=\"coef_abs\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e172a6f",
   "metadata": {},
   "source": [
    "**<font color='red'>Question 4:</font> What are mean squared errors of tuned LASSO predictions on train and holdout sets?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b317c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Mean squared error (train): %.3f\"\n",
    "    % mean_squared_error(y_train, lasso_cv.predict(X_train_scaled))\n",
    ")\n",
    "print(\n",
    "    \"Mean squared error (test): %.3f\"\n",
    "    % mean_squared_error(y_holdout, lasso_cv.predict(X_holdout_scaled))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed451ac",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "**Train a Random Forest with out-of-the-box parameters, setting only random_state to be 17.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bce875",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(random_state=17)\n",
    "forest.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb586e0",
   "metadata": {},
   "source": [
    "**<font color='red'>Question 5:</font> What are mean squared errors of RF model on the training set, in cross-validation (cross_val_score with scoring='neg_mean_squared_error' and other arguments left with default values) and on holdout set?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93897f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Mean squared error (train): %.3f\"\n",
    "    % mean_squared_error(y_train, forest.predict(X_train_scaled))\n",
    ")\n",
    "print(\n",
    "    \"Mean squared error (cv): %.3f\"\n",
    "    % np.mean(\n",
    "        np.abs(\n",
    "            cross_val_score(\n",
    "                forest, X_train_scaled, y_train, scoring=\"neg_mean_squared_error\"\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Mean squared error (test): %.3f\"\n",
    "    % mean_squared_error(y_holdout, forest.predict(X_holdout_scaled))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649ac12c",
   "metadata": {},
   "source": [
    "**Tune the `max_features` and `max_depth` hyperparameters with GridSearchCV and again check mean cross-validation MSE and MSE on holdout set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddf8c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_params = {\"max_depth\": list(range(10, 25)), \"max_features\": list(range(6, 12))}\n",
    "\n",
    "locally_best_forest = GridSearchCV(\n",
    "    RandomForestRegressor(n_jobs=-1, random_state=17),\n",
    "    forest_params,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=True,\n",
    ")\n",
    "locally_best_forest.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e7e72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "locally_best_forest.best_params_, locally_best_forest.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96e0685",
   "metadata": {},
   "source": [
    "**<font color='red'>Question 6:</font> What are mean squared errors of tuned RF model in cross-validation (cross_val_score with scoring='neg_mean_squared_error' and other arguments left with default values) and on holdout set?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c237f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Mean squared error (cv): %.3f\"\n",
    "    % np.mean(\n",
    "        np.abs(\n",
    "            cross_val_score(\n",
    "                locally_best_forest.best_estimator_,\n",
    "                X_train_scaled,\n",
    "                y_train,\n",
    "                scoring=\"neg_mean_squared_error\",\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    \"Mean squared error (test): %.3f\"\n",
    "    % mean_squared_error(y_holdout, locally_best_forest.predict(X_holdout_scaled))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56d9efa",
   "metadata": {},
   "source": [
    "**Output RF's feature importance. Again, it's nice to present it as a DataFrame.**<br>\n",
    "**<font color='red'>Question 7:</font> What is the most important feature, according to the Random Forest model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3c7a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_importance = pd.DataFrame(\n",
    "    locally_best_forest.best_estimator_.feature_importances_,\n",
    "    columns=[\"coef\"],\n",
    "    index=data.columns[:-1],\n",
    ")\n",
    "rf_importance.sort_values(by=\"coef\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce26278",
   "metadata": {},
   "source": [
    "**Make conclusions about the performance of the explored 3 models in this particular prediction task.**\n",
    "\n",
    "The dependency of wine quality on other features in hand is, presumable, non-linear. So Random Forest works better in this task."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "source_map": [
   11,
   31,
   43,
   48,
   56,
   61,
   66,
   68,
   73,
   83,
   90,
   93,
   98,
   107,
   114,
   120,
   127,
   130,
   135,
   141,
   146,
   153,
   155,
   160,
   166,
   171,
   180,
   187,
   190,
   195,
   214,
   219,
   234,
   236,
   241,
   259,
   265,
   272
  ],
  "vscode": {
   "interpreter": {
    "hash": "3f541a8a539371bb1e4218750b65c61ef3b85add88567d9a965338d269b92e2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
